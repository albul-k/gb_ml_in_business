{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Урок 2. #Профилирование пользователей. Сегментация аудитории: unsupervised learning (clustering, LDA/ARTM), supervised (multi/binary classification)#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "План занятия:\n",
    "\n",
    "1. задача сегментации аудитории по интересам - для чего\n",
    "2. тематическое моделирование - получаем эмбединги текстов\n",
    "3. решаем downstream-задачу (профилирование аудитории новостного портала)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассматривать мы все будем в контексте решения конкретной прикладной задачи - задачи оттока"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача сегментации (неформальное определение)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем пользователей на группы, чем-то отличающиеся друг от друга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если же более формально, то:\n",
    "\n",
    "Сегментация клиентской базы — это способ повышения эффективности работы с пользователями путем их распределения по отдельным группам, или сегментам, в соответствии с их запросами и/или потребностями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегментация может быть очень разной:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. когда совершил первую покупку (сколько прошло с момента регистрации до момента покупки)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](payments1.png \"Payments2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. по психотипам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](psycho.png \"Psycho\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. по платежам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](payments.png \"Payments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. По эффективности взаимодействия (uplift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](uplift.png \"Uplift\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. по интересам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](interests.png \"Interests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И еще 100500 вариантов сегментирования, которое может быть полезно. \n",
    "\n",
    "Для чего полезно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. понимание аудитории, способность описать основные группы пользователей и их интересы\n",
    "2. выявление сегментов с максимальной монетизацией\n",
    "3. выбор маркетинговой стратегии\n",
    "4. налаживание эффективного взаимодействия с пользователями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример из жизни (новостной портал)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим, что мы - компания-агрегатор новостей (новостной портал).\n",
    "\n",
    "У нас есть:\n",
    "\n",
    "1. читатели\n",
    "2. новости\n",
    "\n",
    "Для каждого пользователя мы можем за какой-то период (например, 1 день) достать из базы данных список прочитанных им новостей.\n",
    "\n",
    "Для каждой новости мы можем вытащить текст и метаинформацию.\n",
    "\n",
    "### Задача #1: нужно построить модель прогнозирования оттока - это наша downstream-задача. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам нужны:\n",
    "\n",
    "1. векторное представление пользователя\n",
    "2. сегменты, описывающие интересы пользователя\n",
    "\n",
    "p.s. в контексте нашей задачи - это одно и то же"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### С чего начнем?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С векторного представления и сегментов новостей!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть два очевидных варианта как это сделать:\n",
    "\n",
    "1. многоклассовая классификация\n",
    "2. кластеризация документов с последующей попыткой их (кластера) интерпретировать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. для классификации нам нужно сначала разметить новости - привлечение ручного труда"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача тематического моделирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Неформально!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- на свете бывают темы (заранее неизвестные), которые отражают то, о чём могут быть части документа;\n",
    "- каждая тема – это распределение вероятностей на словах, т.е. мешок слов, из которого можно с разной вероятностью вытащить разные слова;\n",
    "- каждый документ – это смесь тем, т.е. распределение вероятностей на темах, кубик, который можно кинуть;\n",
    "- процесс порождения каждого слова состоит в том, чтобы сначала выбрать тему по распределению, соответствующему документу, а затем выбрать слово из распределения, соответствующего этой теме."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятностные модели удобно понимать и представлять в виде порождающих процессов (generative processes), когда мы последовательно описываем, как порождается одна единица данных, вводя по ходу дела все вероятностные предположения, которые мы в этой модели делаем. Соответственно, порождающий процесс для LDA должен последовательно описывать, как мы порождаем каждое слово каждого документа. И вот как это происходит (здесь и далее я буду предполагать, что длина каждого документа задана – её тоже можно добавить в модель, но обычно это ничего нового не даёт):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. для каждой темы t выбираем вектор phi_t - распределение слов в теме\n",
    "\n",
    "2. для каждого документа d:\n",
    "\n",
    "    2.1 выбираем Theta_d - распределение тем в документе\n",
    "    \n",
    "    2.2 для каждого из слов документа w:\n",
    "        2.2.1 выбираем тему z~Theta_d\n",
    "        2.2.2 выбираем слово w~p(w|z, phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lda](lda_simple.png \"LDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ист. https://habr.com/ru/company/surfingbird/blog/230103/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Чуть более формально"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Терминология:\n",
    "\n",
    "1. документ - коллекция слов \n",
    "2. тема - набор токенов (слов), совместно часто встречающихся в документах\n",
    "\n",
    "Более формально:\n",
    "\n",
    "1. тема - условное распределение на множестве терминов, p(w|t)\n",
    "2. тематический профиль документа - условное распределение тем p(t|d)\n",
    "\n",
    "Вопрос: что же нам дано (в терминах условной вероятности)?\n",
    "\n",
    "Ответ: условное распределение слов в документах - p(w|d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прекрасное объяснение от Воронцова - http://www.machinelearning.ru/wiki/images/d/d5/Voron17survey-artm.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тематическая модель позволяет нам получить p(w|t), p(t|d) по известным p(w|d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ab_split](tm1.png \"TM1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python37764bit3fbe5ae206bf467f9f636d844c57ff6e",
   "display_name": "Python 3.7.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "ca35beca1e73f0e8e48de5d26c91c8a581bc78491f6978c6ebd776970508bb03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}